{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32de967f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (4.11.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from trio~=0.17->selenium) (1.1.3)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d9a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c9d8784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = \n",
    "#https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: \n",
    "#A) Rank \n",
    "#B) Name \n",
    "#C) Artist \n",
    "#D) Upload date \n",
    "#E) Views \n",
    "\n",
    "driver = webdriver.Chrome() \n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b62df424",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_Videos = []\n",
    "table = driver.find_element(By.XPATH, '//table[@class=\"wikitable sortable jquery-tablesorter\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c17ff163",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = table.find_elements(By.TAG_NAME, 'tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea7f58d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b1ce35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows[1:]: #skipping header row\n",
    "    cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "    if len(cells) >= 5:\n",
    "        rank = cells[0].text\n",
    "        name = cells[1].text\n",
    "        artist = cells[2].text\n",
    "        upload_date = cells[4].text\n",
    "        views = cells[3].text\n",
    "        Best_Videos.append({\"Rank\": rank, \"Name\": name, \"Artist\": artist, \"Date\": upload_date,\"Views\": views})\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84bb3490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[16]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[18]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[27]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[28]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[29]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[30]</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[35]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[36]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[38]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[39]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Roar\"[40]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[42]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Sorry\"[43]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[44]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Thinking Out Loud\"[45]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"[46]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[48]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Faded\"[49]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"[51]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Lean On\"[52]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Bailando\"[53]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[16]   \n",
       "3    4.                                  \"Bath Song\"[17]   \n",
       "4    5.                               \"Shape of You\"[18]   \n",
       "5    6.                              \"See You Again\"[21]   \n",
       "6    7.                          \"Wheels on the Bus\"[26]   \n",
       "7    8.                \"Phonics Song with Two Words\"[27]   \n",
       "8    9.                                \"Uptown Funk\"[28]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[29]   \n",
       "10  11.                              \"Gangnam Style\"[30]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[35]   \n",
       "12  13.                             \"Dame Tu Cosita\"[36]   \n",
       "13  14.                                     \"Axel F\"[37]   \n",
       "14  15.                                      \"Sugar\"[38]   \n",
       "15  16.                             \"Counting Stars\"[39]   \n",
       "16  17.                                       \"Roar\"[40]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[41]   \n",
       "18  19.           \"Waka Waka (This Time for Africa)\"[42]   \n",
       "19  20.                                      \"Sorry\"[43]   \n",
       "20  21.                             \"Lakdi Ki Kathi\"[44]   \n",
       "21  22.                          \"Thinking Out Loud\"[45]   \n",
       "22  23.                                 \"Dark Horse\"[46]   \n",
       "23  24.          \"Humpty the train on a fruits ride\"[47]   \n",
       "24  25.                                    \"Perfect\"[48]   \n",
       "25  26.                                      \"Faded\"[49]   \n",
       "26  27.                                 \"Let Her Go\"[50]   \n",
       "27  28.                             \"Girls Like You\"[51]   \n",
       "28  29.                                    \"Lean On\"[52]   \n",
       "29  30.                                   \"Bailando\"[53]   \n",
       "\n",
       "                                               Artist               Date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                         Miroshka TV  February 27, 2018   \n",
       "10                                        officialpsy      July 15, 2012   \n",
       "11                                         Get Movies   January 31, 2012   \n",
       "12                                      Ultra Records      April 5, 2018   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                                        OneRepublic       May 31, 2013   \n",
       "16                                         Katy Perry  September 5, 2013   \n",
       "17                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "18                                            Shakira       June 4, 2010   \n",
       "19                                      Justin Bieber   October 22, 2015   \n",
       "20                                       Jingle Toons      June 14, 2018   \n",
       "21                                         Ed Sheeran    October 7, 2014   \n",
       "22                                         Katy Perry  February 20, 2014   \n",
       "23      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "24                                         Ed Sheeran   November 9, 2017   \n",
       "25                                        Alan Walker   December 3, 2015   \n",
       "26                                          Passenger      July 25, 2012   \n",
       "27                                           Maroon 5       May 31, 2018   \n",
       "28                               Major Lazer Official     March 22, 2015   \n",
       "29                                   Enrique Iglesias     April 11, 2014   \n",
       "\n",
       "    Views  \n",
       "0   13.29  \n",
       "1    8.25  \n",
       "2    6.78  \n",
       "3    6.38  \n",
       "4    6.07  \n",
       "5    6.01  \n",
       "6    5.53  \n",
       "7    5.47  \n",
       "8    5.02  \n",
       "9    4.96  \n",
       "10   4.88  \n",
       "11   4.56  \n",
       "12   4.43  \n",
       "13   4.04  \n",
       "14   3.93  \n",
       "15   3.86  \n",
       "16   3.86  \n",
       "17   3.76  \n",
       "18   3.71  \n",
       "19   3.70  \n",
       "20   3.67  \n",
       "21   3.65  \n",
       "22   3.58  \n",
       "23   3.54  \n",
       "24   3.53  \n",
       "25   3.51  \n",
       "26   3.50  \n",
       "27   3.47  \n",
       "28   3.45  \n",
       "29   3.45  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(Best_Videos)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e0da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question2. Scrape the details team India’s international fixtures from bcci.tv. \n",
    "#Url = https://www.bcci.tv/.\n",
    "#You need to find following details: \n",
    "#A) Match title (I.e. 1 ODI) \n",
    "#B) Series \n",
    "#C) Place \n",
    "#D) Date \n",
    "#E) Time \n",
    "#Note: - From bcci.tv home page you have reach to the international fixture page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b82ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() \n",
    "driver.get('https://www.bcci.tv/.') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb3f978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e8a12ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_Title = []\n",
    "title_tags=driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "for i in title_tags:\n",
    "    title=i.text\n",
    "    Match_Title.append(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24072603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dbe2330",
   "metadata": {},
   "outputs": [],
   "source": [
    "Series = []\n",
    "series_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-card-middle__inner d-flex justify-content-between\"]')\n",
    "for i in series_tags:\n",
    "    SERIES=i.text\n",
    "    Series.append(SERIES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29780e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date = []\n",
    "Dates_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in Dates_tags:\n",
    "    dates=i.text\n",
    "    Date.append(dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1016503",
   "metadata": {},
   "outputs": [],
   "source": [
    "Time = []\n",
    "time_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in time_tags:\n",
    "    Times=i.text\n",
    "    Time.append(Times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "927367cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quarter Final 1 -</td>\n",
       "      <td>India Women\\nvs\\nMalaysia Women</td>\n",
       "      <td>21 SEP 2023</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>India\\nvs\\nAustralia</td>\n",
       "      <td>22 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>India\\nvs\\nAustralia</td>\n",
       "      <td>24 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>India\\nvs\\nAustralia</td>\n",
       "      <td>27 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>India\\nvs\\nEngland</td>\n",
       "      <td>30 SEP 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>India\\nvs\\nTBD</td>\n",
       "      <td>3 OCT 2023</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>India\\nvs\\nNetherlands</td>\n",
       "      <td>3 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>India\\nvs\\nAustralia</td>\n",
       "      <td>8 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Title                           Series         Date  \\\n",
       "0  Quarter Final 1 -  India Women\\nvs\\nMalaysia Women  21 SEP 2023   \n",
       "1          1st ODI -             India\\nvs\\nAustralia  22 SEP 2023   \n",
       "2          2nd ODI -             India\\nvs\\nAustralia  24 SEP 2023   \n",
       "3          3rd ODI -             India\\nvs\\nAustralia  27 SEP 2023   \n",
       "4          1st ODI -               India\\nvs\\nEngland  30 SEP 2023   \n",
       "5         1st T20I -                   India\\nvs\\nTBD   3 OCT 2023   \n",
       "6          2nd ODI -           India\\nvs\\nNetherlands   3 OCT 2023   \n",
       "7          1st ODI -             India\\nvs\\nAustralia   8 OCT 2023   \n",
       "\n",
       "          Time  \n",
       "0  6:30 AM IST  \n",
       "1  1:30 PM IST  \n",
       "2  1:30 PM IST  \n",
       "3  1:30 PM IST  \n",
       "4  2:00 PM IST  \n",
       "5  6:30 AM IST  \n",
       "6  2:00 PM IST  \n",
       "7  2:00 PM IST  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Title':Match_Title,'Series':Series,'Date':Date,'Time':Time})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b68ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a2a2c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "#Url = http://statisticstimes.com/\n",
    "#You have to find following details: A)\n",
    "#Rank \n",
    "#B) State \n",
    "#C) GSDP(18-19)- at current prices \n",
    "#D) GSDP(19-20)- at current prices \n",
    "#E) Share(18-19) \n",
    "#F) GDP($ billion) \n",
    "#Note: - From statisticstimes home page you have to reach to economy page through code.\n",
    "\n",
    "driver = webdriver.Chrome() \n",
    "driver.get('http://statisticstimes.com/') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a8cc48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "economy_filter = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "economy_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c5e7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_INDIA = []\n",
    "table = driver.find_element(By.XPATH, '//table[@class=\"display dataTable\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c4d6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = table.find_elements(By.TAG_NAME, 'tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3126f28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows[1:]: #skipping header row\n",
    "    cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "    if len(cells) >= 6:\n",
    "        State = cells[1].text\n",
    "        GSD = cells[3].text\n",
    "        GSDP = cells[2].text\n",
    "        Share = cells[4].text\n",
    "        GDP = cells[5].text\n",
    "        GDP_INDIA.append({\"Rank\": State, \"Name\": GSD, \"Artist\": GSDP, \"Date\": Share,\"Views\": GDP})\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2c31f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Date</th>\n",
       "      <th>Views</th>\n",
       "      <th>State</th>\n",
       "      <th>GSD</th>\n",
       "      <th>GSDP</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP</th>\n",
       "      <th>States</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>India</td>\n",
       "      <td>18,886,957</td>\n",
       "      <td>20,351,013</td>\n",
       "      <td></td>\n",
       "      <td>2,869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Rank        Name      Artist    Date    Views State  \\\n",
       "0                  Maharashtra   2,632,792           -  13.94%  399.921   NaN   \n",
       "1                   Tamil Nadu   1,630,208   1,845,853   8.63%  247.629   NaN   \n",
       "2                Uttar Pradesh   1,584,764   1,687,818   8.39%  240.726   NaN   \n",
       "3                      Gujarat   1,502,899           -   7.96%  228.290   NaN   \n",
       "4                    Karnataka   1,493,127   1,631,977   7.91%  226.806   NaN   \n",
       "..                         ...         ...         ...     ...      ...   ...   \n",
       "165                   Nagaland      27,283           -   0.14%    4.144   NaN   \n",
       "166          Arunachal Pradesh      24,603           -   0.13%    3.737   NaN   \n",
       "167                    Mizoram      22,287      26,503   0.12%    3.385   NaN   \n",
       "168  Andaman & Nicobar Islands           -           -       -        -   NaN   \n",
       "169                      India  18,886,957  20,351,013            2,869   NaN   \n",
       "\n",
       "     GSD GSDP Share  GDP States  \n",
       "0    NaN  NaN   NaN  NaN    NaN  \n",
       "1    NaN  NaN   NaN  NaN    NaN  \n",
       "2    NaN  NaN   NaN  NaN    NaN  \n",
       "3    NaN  NaN   NaN  NaN    NaN  \n",
       "4    NaN  NaN   NaN  NaN    NaN  \n",
       "..   ...  ...   ...  ...    ...  \n",
       "165  NaN  NaN   NaN  NaN    NaN  \n",
       "166  NaN  NaN   NaN  NaN    NaN  \n",
       "167  NaN  NaN   NaN  NaN    NaN  \n",
       "168  NaN  NaN   NaN  NaN    NaN  \n",
       "169  NaN  NaN   NaN  NaN    NaN  \n",
       "\n",
       "[170 rows x 11 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(GDP_INDIA)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "451291a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout occurred while searching for the product.\n",
      "Timeout occurred while searching for the product.\n",
      "Timeout occurred while searching for the product.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 61\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimeout occurred while searching for the product.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Extract the table rows\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mTAG_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows:\n\u001b[0;32m     64\u001b[0m     cols \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mTAG_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'table' is not defined"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Set up the WebDriver (Specify the path to your WebDriver)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the website\n",
    "url = 'http://statisticstimes.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# Click on 'Economy' in the top menu\n",
    "try:\n",
    "    economy_link = WebDriverWait(driver, 30).until(\n",
    "        EC.presence_of_element_located((By.LINK_TEXT, 'Economy')))\n",
    "\n",
    "    economy_link.click()\n",
    "    \n",
    "except TimeoutException:\n",
    "    print(\"Timeout occurred while searching for the product.\")\n",
    "    \n",
    "# Click on 'India' in the 'India/States' section\n",
    "try:\n",
    "    india_link = WebDriverWait(driver, 30).until(\n",
    "        EC.presence_of_element_located((By.PARTIAL_LINK_TEXT, 'India/States')))\n",
    "    india_link.click()\n",
    "except TimeoutException:\n",
    "    print(\"Timeout occurred while searching for the product.\")\n",
    "    \n",
    "    \n",
    "\n",
    "# Click on 'GDP of Indian states' in the 'GDP of Indian states' section\n",
    "try:\n",
    "    gdp_link = WebDriverWait(driver, 30).until(\n",
    "        EC.presence_of_element_located((By.PARTIAL_LINK_TEXT, 'GDP of Indian states')))\n",
    "    gdp_link.click()\n",
    "except TimeoutException:\n",
    "    print(\"Timeout occurred while searching for the product.\")\n",
    "    \n",
    "\n",
    "# Scrape the data\n",
    "data = []\n",
    "\n",
    "# Wait for the table to load\n",
    "try:\n",
    "    table = WebDriverWait(driver, 30).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, 'dataTables_wrapper')))\n",
    "except TimeoutException:\n",
    "    print(\"Timeout occurred while searching for the product.\")\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "# Extract the table rows\n",
    "rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "for row in rows:\n",
    "    cols = row.find_elements(By.TAG_NAME, 'td')\n",
    "    if len(cols) >= 7:  # Ensure it's a data row\n",
    "        rank = cols[0].text\n",
    "        state = cols[1].text\n",
    "        gsdp_18_19 = cols[2].text\n",
    "        gsdp_19_20 = cols[3].text\n",
    "        share_18_19 = cols[4].text\n",
    "        gdp_billion = cols[5].text\n",
    "\n",
    "        data.append({\n",
    "            'Rank': rank,\n",
    "            'State': state,\n",
    "            'GSDP(18-19)': gsdp_18_19,\n",
    "            'GSDP(19-20)': gsdp_19_20,\n",
    "            'Share(18-19)': share_18_19,\n",
    "            'GDP($ billion)': gdp_billion\n",
    "        })\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the scraped data\n",
    "print(df)\n",
    "\n",
    "# Close the WebDriver\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "681a6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 4 Scrape the details of trending repositories on Github.com. \n",
    "#Url = https://github.com/\n",
    "#You have to find the following details: \n",
    "#A) Repository title \n",
    "#B) Repository description \n",
    "#C) Contributors count \n",
    "#D) Language used \n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://github.com/trending')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c6007cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_titles = []\n",
    "Repo_titles=driver.find_elements(By.XPATH,'//span[@class=\"text-normal\"]')\n",
    "for i in Repo_titles:\n",
    "    title=i.text\n",
    "    repo_titles.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29a742e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_description = []\n",
    "description_titles=driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in description_titles:\n",
    "    define=i.text\n",
    "    Repository_description.append(define)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0893ca6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>krahets /</td>\n",
       "      <td>《Hello 算法》：动画图解、一键运行的数据结构与算法教程，支持 Java, C++, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mylxsw /</td>\n",
       "      <td>AIdea 是一款支持 GPT 以及国产大语言模型通义千问、文心一言等，支持 Stable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oven-sh /</td>\n",
       "      <td>Incredibly fast JavaScript runtime, bundler, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linkedin /</td>\n",
       "      <td>At LinkedIn, we are using this curriculum for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dair-ai /</td>\n",
       "      <td>Explanation to key concepts in ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Developer-Y /</td>\n",
       "      <td>List of Computer Science courses with video le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>microsoft /</td>\n",
       "      <td>24 Lessons, 12 Weeks, Get Started as a Web Dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mylxsw /</td>\n",
       "      <td>AIdea 是一款支持 GPT 以及国产大语言模型通义千问、文心一言等，支持 Stable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>eduard-permyakov /</td>\n",
       "      <td>A fully lock-free game engine written in C++20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ryanmcdermott /</td>\n",
       "      <td>🛁 Clean Code concepts adapted for JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ironclad /</td>\n",
       "      <td>The open-source visual AI programming environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Snoopy1866 /</td>\n",
       "      <td>李跳跳自定义规则</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>trekhleb /</td>\n",
       "      <td>📝 Algorithms and data structures implemented i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>modularml /</td>\n",
       "      <td>The Mojo Programming Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>microsoft /</td>\n",
       "      <td>Build high-quality LLM apps - from prototyping...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>honojs /</td>\n",
       "      <td>Ultrafast web framework for the Edges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wagtail /</td>\n",
       "      <td>A Django content management system focused on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tencent-ailab /</td>\n",
       "      <td>The image prompt adapter is designed to enable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>w-okada /</td>\n",
       "      <td>リアルタイムボイスチェンジャー Realtime Voice Changer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>guoyww /</td>\n",
       "      <td>Official implementation of AnimateDiff.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>uNetworking /</td>\n",
       "      <td>Simple, secure &amp; standards compliant web serve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>openai-translator /</td>\n",
       "      <td>基于 ChatGPT API 的划词翻译浏览器插件和跨平台桌面端应用 - Browser e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>squidfunk /</td>\n",
       "      <td>Documentation that simply works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ossu /</td>\n",
       "      <td>🎓 Path to a free self-taught education in Comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DataTalksClub /</td>\n",
       "      <td>The code from the Machine Learning Bookcamp bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Repository Title                             Repository description\n",
       "0             krahets /  《Hello 算法》：动画图解、一键运行的数据结构与算法教程，支持 Java, C++, P...\n",
       "1              mylxsw /  AIdea 是一款支持 GPT 以及国产大语言模型通义千问、文心一言等，支持 Stable ...\n",
       "2             oven-sh /  Incredibly fast JavaScript runtime, bundler, t...\n",
       "3            linkedin /  At LinkedIn, we are using this curriculum for ...\n",
       "4             dair-ai /                  Explanation to key concepts in ML\n",
       "5         Developer-Y /  List of Computer Science courses with video le...\n",
       "6           microsoft /  24 Lessons, 12 Weeks, Get Started as a Web Dev...\n",
       "7              mylxsw /  AIdea 是一款支持 GPT 以及国产大语言模型通义千问、文心一言等，支持 Stable ...\n",
       "8    eduard-permyakov /     A fully lock-free game engine written in C++20\n",
       "9       ryanmcdermott /       🛁 Clean Code concepts adapted for JavaScript\n",
       "10           Ironclad /  The open-source visual AI programming environm...\n",
       "11         Snoopy1866 /                                           李跳跳自定义规则\n",
       "12           trekhleb /  📝 Algorithms and data structures implemented i...\n",
       "13          modularml /                      The Mojo Programming Language\n",
       "14          microsoft /  Build high-quality LLM apps - from prototyping...\n",
       "15             honojs /              Ultrafast web framework for the Edges\n",
       "16            wagtail /  A Django content management system focused on ...\n",
       "17      tencent-ailab /  The image prompt adapter is designed to enable...\n",
       "18            w-okada /             リアルタイムボイスチェンジャー Realtime Voice Changer\n",
       "19             guoyww /            Official implementation of AnimateDiff.\n",
       "20        uNetworking /  Simple, secure & standards compliant web serve...\n",
       "21  openai-translator /  基于 ChatGPT API 的划词翻译浏览器插件和跨平台桌面端应用 - Browser e...\n",
       "22          squidfunk /                    Documentation that simply works\n",
       "23               ossu /  🎓 Path to a free self-taught education in Comp...\n",
       "24      DataTalksClub /  The code from the Machine Learning Bookcamp bo..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Repository Title':repo_titles,'Repository description':Repository_description})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccbe7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/\n",
    "#You have to find the following details: \n",
    "#A) Song name \n",
    "#B) Artist name \n",
    "#C) Last week rank \n",
    "#D) Peak rank \n",
    "#E) Weeks on board \n",
    "#Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n",
    "    \n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https:/www.billboard.com/')       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f156ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_filter = driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "chart_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "726c73e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_filter = driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[3]/a')\n",
    "view_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69d5e106",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_songs = []\n",
    "table = driver.find_element(By.XPATH, '/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "233ab0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = table.find_elements(By.TAG_NAME, 'div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad7f09b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows[1:]: #skipping header row\n",
    "    cells = row.find_elements(By.TAG_NAME, 'li')\n",
    "    if len(cells) >= 5:\n",
    "        rank = cells[0].text\n",
    "        song_name = cells[1].text\n",
    "        last_week_rank = cells[3].text\n",
    "        peak_rank = cells[4].text\n",
    "        weeks_on_board = cells[5].text\n",
    "        Best_songs.append({\"Rank\": rank, \"Name\": song_name, \"Last week\": last_week_rank, \"peak\": peak_rank,\"Weeks on board\": weeks_on_board})\n",
    "    else:\n",
    "        pass\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95f76fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Last week</th>\n",
       "      <th>peak</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Vampire\\nOlivia Rodrigo\\n9\\n1\\n11</td>\n",
       "      <td>Vampire\\nOlivia Rodrigo</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>Paint The Town Red\\nDoja Cat\\n1\\n1\\n6</td>\n",
       "      <td>Paint The Town Red\\nDoja Cat</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>I Remember Everything\\nZach Bryan Featuring Ka...</td>\n",
       "      <td>I Remember Everything\\nZach Bryan Featuring Ka...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>Fast Car\\nLuke Combs\\n3\\n2\\n25</td>\n",
       "      <td>Fast Car\\nLuke Combs</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>Cruel Summer\\nTaylor Swift\\n4\\n3\\n19</td>\n",
       "      <td>Cruel Summer\\nTaylor Swift</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96\\nRE- ENTRY</td>\n",
       "      <td></td>\n",
       "      <td>Lagunas\\nPeso Pluma &amp; Jasiel Nunez\\n-\\n77\\n9</td>\n",
       "      <td>Lagunas\\nPeso Pluma &amp; Jasiel Nunez</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td></td>\n",
       "      <td>Sittin' On Top Of The World\\nBurna Boy\\n86\\n80\\n3</td>\n",
       "      <td>Sittin' On Top Of The World\\nBurna Boy</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td></td>\n",
       "      <td>Rubicon\\nPeso Pluma\\n95\\n63\\n11</td>\n",
       "      <td>Rubicon\\nPeso Pluma</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td></td>\n",
       "      <td>TQM\\nFuerza Regida\\n89\\n34\\n17</td>\n",
       "      <td>TQM\\nFuerza Regida</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td></td>\n",
       "      <td>Amargura\\nKarol G\\n91\\n85\\n5</td>\n",
       "      <td>Amargura\\nKarol G</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rank Name                                          Last week  \\\n",
       "0               1                       Vampire\\nOlivia Rodrigo\\n9\\n1\\n11   \n",
       "1               2                   Paint The Town Red\\nDoja Cat\\n1\\n1\\n6   \n",
       "2               3       I Remember Everything\\nZach Bryan Featuring Ka...   \n",
       "3               4                          Fast Car\\nLuke Combs\\n3\\n2\\n25   \n",
       "4               5                    Cruel Summer\\nTaylor Swift\\n4\\n3\\n19   \n",
       "..            ...  ...                                                ...   \n",
       "95  96\\nRE- ENTRY            Lagunas\\nPeso Pluma & Jasiel Nunez\\n-\\n77\\n9   \n",
       "96             97       Sittin' On Top Of The World\\nBurna Boy\\n86\\n80\\n3   \n",
       "97             98                         Rubicon\\nPeso Pluma\\n95\\n63\\n11   \n",
       "98             99                          TQM\\nFuerza Regida\\n89\\n34\\n17   \n",
       "99            100                            Amargura\\nKarol G\\n91\\n85\\n5   \n",
       "\n",
       "                                                 peak Weeks on board  \n",
       "0                             Vampire\\nOlivia Rodrigo                 \n",
       "1                        Paint The Town Red\\nDoja Cat                 \n",
       "2   I Remember Everything\\nZach Bryan Featuring Ka...                 \n",
       "3                                Fast Car\\nLuke Combs                 \n",
       "4                          Cruel Summer\\nTaylor Swift                 \n",
       "..                                                ...            ...  \n",
       "95                 Lagunas\\nPeso Pluma & Jasiel Nunez                 \n",
       "96             Sittin' On Top Of The World\\nBurna Boy                 \n",
       "97                                Rubicon\\nPeso Pluma                 \n",
       "98                                 TQM\\nFuerza Regida                 \n",
       "99                                  Amargura\\nKarol G                 \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(Best_songs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5593f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question6. Scrape the details of Highest selling novels. \n",
    "#compare \n",
    "#A) Book name \n",
    "#B) Author name \n",
    "#C) Volumes sold \n",
    "#D) Publisher \n",
    "#E) Genre \n",
    "#Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5696c9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver = webdriver.Chrome() \n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58b11132",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_Novel = []\n",
    "table = driver.find_element(By.XPATH, '//table[@class=\"in-article sortable\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c4d837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = table.find_elements(By.TAG_NAME, 'tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c5ae5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows[1:]: #skipping header row\n",
    "    cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "    if len(cells) >= 5:\n",
    "        rank = cells[0].text\n",
    "        book_name = cells[1].text\n",
    "        author_name = cells[2].text\n",
    "        volumes_sold = cells[3].text\n",
    "        publisher = cells[4].text\n",
    "        genre = cells[5].text\n",
    "        Best_Novel.append({\"Rank\": rank, \"BOOK_NAME\": book_name, \"Author\": author_name, \"Volume\": volumes_sold,\"Publisher\": publisher,\"Genre\":genre})\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a541c9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>BOOK_NAME</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                          BOOK_NAME            Author  \\\n",
       "0     1                                  Da Vinci Code,The        Brown, Dan   \n",
       "1     2               Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2     3           Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3     4          Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4     5                               Fifty Shades of Grey      James, E. L.   \n",
       "..  ...                                                ...               ...   \n",
       "95   96                                          Ghost,The    Harris, Robert   \n",
       "96   97                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97   98              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98   99  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  100  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "       Volume        Publisher                        Genre  \n",
       "0   5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1   4,475,152       Bloomsbury           Children's Fiction  \n",
       "2   4,200,654       Bloomsbury           Children's Fiction  \n",
       "3   4,179,479       Bloomsbury           Children's Fiction  \n",
       "4   3,758,936     Random House              Romance & Sagas  \n",
       "..        ...              ...                          ...  \n",
       "95    807,311     Random House   General & Literary Fiction  \n",
       "96    794,201          Penguin        Food & Drink: General  \n",
       "97    792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98    791,507            Orion           Biography: General  \n",
       "99    791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(Best_Novel)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4cdd983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTIO7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "#Url = https://www.imdb.com/list/ls095964455/ You \n",
    "#have to find the following details: \n",
    "#A) Name \n",
    "#B) Year span \n",
    "#C) Genre \n",
    "#D) Run time \n",
    "#E) Ratings \n",
    "#F) Votes \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb3532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6996180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []\n",
    "name_titles=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "for i in name_titles:\n",
    "    names=i.text\n",
    "    Name.append(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f1c3283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d9472c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Year = []\n",
    "year_titles=driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "for i in year_titles:\n",
    "    years=i.text\n",
    "    Year.append(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a182fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = []\n",
    "genres_titles=driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "for i in genres_titles:\n",
    "    Genre=i.text\n",
    "    genre.append(Genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dcaf1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes = []\n",
    "Time_titles=driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "for i in Time_titles:\n",
    "    Times=i.text\n",
    "    runtimes.append(Times)\n",
    "\n",
    "rating = []\n",
    "rating_titles=driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]')\n",
    "for i in rating_titles:\n",
    "    Ratings=i.text\n",
    "    rating.append(Ratings)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e087b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>year_spans</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name   year_spans                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings  \n",
       "0    57 min     9.2  \n",
       "1    51 min     8.7  \n",
       "2    44 min     8.1  \n",
       "3    60 min     7.5  \n",
       "4    43 min     7.6  \n",
       "..      ...     ...  \n",
       "95   42 min     7.5  \n",
       "96   50 min     7.8  \n",
       "97   42 min     8.1  \n",
       "98   45 min       7  \n",
       "99  572 min     8.6  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Name':Name,'year_spans':Year,'Genre':genre,'Run time':runtimes,'Ratings':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f6fb058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question8. Details of Datasets from UCI machine learning repositories. \n",
    "#Url = https://archive.ics.uci.edu/\n",
    "#You have to find the following details: \n",
    "#A) Dataset name \n",
    "#B) Data type \n",
    "#C) Task \n",
    "#D) Attribute type \n",
    "#E) No of instances \n",
    "#F) No of attribute G) Year \n",
    "#Note: - from the home page you have to go to the Show All Dataset page through code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfadccfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24fe9e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52439142",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc49dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = []\n",
    "name_tags=driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for i in name_tags:\n",
    "    Names=i.text\n",
    "    dataset_name.append(Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d8e4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a32d00c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_types) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e98ddcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "task_tags=driver.find_elements(By.XPATH,'//p[@class=\"truncate\"]')\n",
    "for i in task_tags:\n",
    "    TASK=i.text\n",
    "    tasks.append(TASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd9df6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Tasks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>: Simulated Data set of Iraqi tourism places</td>\n",
       "      <td>Simulated Data set of Iraqi tourism places wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181 early modern English plays: Transcriptions...</td>\n",
       "      <td>English plays (1585-1610), transcribed from ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.4 GHZ Indoor Channel Measurements</td>\n",
       "      <td>Measurement of the S21,consists of 10 sweeps, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2D elastodynamic metamaterials</td>\n",
       "      <td>This dataset list the location and width of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D Road Network (North Jutland, Denmark)</td>\n",
       "      <td>3D road network with highly accurate elevation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3W dataset</td>\n",
       "      <td>The first realistic and public dataset with ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9mers from cullpdb</td>\n",
       "      <td>The dataset consists of protein fragments of l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A study of Asian Religious and Biblical Texts</td>\n",
       "      <td>Mainly from Project Gutenberg, we combine Upan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAAI 2013 Accepted Papers</td>\n",
       "      <td>This data set compromises the metadata for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAAI 2014 Accepted Papers</td>\n",
       "      <td>This data set compromises the metadata for the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Dataset Name  \\\n",
       "0       : Simulated Data set of Iraqi tourism places   \n",
       "1  181 early modern English plays: Transcriptions...   \n",
       "2                2.4 GHZ Indoor Channel Measurements   \n",
       "3                     2D elastodynamic metamaterials   \n",
       "4           3D Road Network (North Jutland, Denmark)   \n",
       "5                                         3W dataset   \n",
       "6                                 9mers from cullpdb   \n",
       "7      A study of Asian Religious and Biblical Texts   \n",
       "8                          AAAI 2013 Accepted Papers   \n",
       "9                          AAAI 2014 Accepted Papers   \n",
       "\n",
       "                                               Tasks  \n",
       "0  Simulated Data set of Iraqi tourism places wit...  \n",
       "1  English plays (1585-1610), transcribed from ea...  \n",
       "2  Measurement of the S21,consists of 10 sweeps, ...  \n",
       "3  This dataset list the location and width of th...  \n",
       "4  3D road network with highly accurate elevation...  \n",
       "5  The first realistic and public dataset with ra...  \n",
       "6  The dataset consists of protein fragments of l...  \n",
       "7  Mainly from Project Gutenberg, we combine Upan...  \n",
       "8  This data set compromises the metadata for the...  \n",
       "9  This data set compromises the metadata for the...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Dataset Name':dataset_name, 'Tasks':tasks})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65122050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
